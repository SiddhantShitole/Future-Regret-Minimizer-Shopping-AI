## ğŸš€ Future-Regret Minimizer Shopping AI

An AI-powered web application that predicts post-purchase regret probability before checkout and suggests lower-risk alternatives to help users make smarter financial decisions.

## ğŸ§  Problem Statement

Many consumers experience regret after purchases due to:

Impulse buying

Budget overspending

Behavioral deviation from past spending

Repeated return patterns

This project aims to predict regret risk before purchase using machine learning and provide actionable recommendations.

âœ¨ Key Features

ğŸ”® Regret Probability Prediction (0â€“100%)

ğŸ’¸ Budget Stress Score

ğŸ“‰ Long-Term Satisfaction Estimate

ğŸ§  Behavioral explanation (â€œWhy this score?â€)

ğŸ” AI-suggested lower-regret alternative

âš¡ Real-time ML inference

ğŸ¨ Modern AI-style UI

ğŸ— System Architecture
Frontend (Next.js - Vercel)
        â†“
Next.js API Route
        â†“
FastAPI Inference Server
        â†“
PyTorch TorchScript Model
Why Separate ML Server?

Vercel serverless functions do not support full PyTorch runtime

Enables scalable microservice architecture

Industry-standard ML deployment pattern

ğŸ›  Tech Stack
Frontend

Next.js (App Router)

TypeScript

Tailwind CSS

pnpm

Backend (Inference)

FastAPI

PyTorch (TorchScript)

Uvicorn

ML Model

PyTorch

Multi-output regression

Synthetic behavioral dataset

AMD ROCm compatible

Database (Planned)

Supabase (Free tier)

Deployment

Vercel (Frontend)

Render / Railway (ML backend)

ğŸ“Š Machine Learning Overview
Input Features

Product price

User budget

Past average spending

Return rate

Spending deviation

Outputs

Regret Probability (0â€“100%)

Budget Stress Score (0â€“100%)

Long-Term Satisfaction (derived as 100 âˆ’ regret)

Model Type

Multi-output regression

Fully connected neural network

Trained on synthetic behavioral dataset

Exported via TorchScript for production inference

ğŸ“ Project Structure
Future-Regret-Minimizer/
â”‚
â”œâ”€â”€ app/                  # Next.js frontend
â”œâ”€â”€ components/           # UI components
â”œâ”€â”€ lib/                  # Utility logic
â”œâ”€â”€ ml-model/             # Training code
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ regret_model.pt
â”‚
â”œâ”€â”€ ml-inference/         # FastAPI server
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ regret_model.pt
â”‚
â””â”€â”€ README.md
âš™ï¸ Running Locally
1ï¸âƒ£ Start ML Inference Server
cd ml-inference
python -m uvicorn main:app --reload

Runs at:

http://127.0.0.1:8000

Swagger Docs:

http://127.0.0.1:8000/docs
2ï¸âƒ£ Start Frontend
pnpm dev

Runs at:

http://localhost:3000
ğŸ“ˆ Example Prediction

Input:

{
  "price": 20000,
  "user_budget": 50000,
  "past_avg_spending": 15000,
  "return_rate": 0.2,
  "spending_deviation": 0.3
}

Output:

{
  "regret_probability": 19.57,
  "budget_stress": 28.1,
  "satisfaction": 80.43
}
ğŸ” How It Works

User enters product & financial data.

Frontend sends request to backend.

FastAPI loads TorchScript model.

Model predicts regret metrics.

Business logic enforces logical constraints.

UI displays:

Risk meter

Explanation

Alternative recommendation

ğŸ¯ Use Cases

E-commerce decision support

Financial wellness apps

Impulse buying prevention tools

Behavioral spending analytics

Smart checkout assistants

ğŸš€ Future Improvements

Real user behavioral tracking (Supabase)

Personalized regret modeling per user

Reinforcement learning adaptation

ONNX optimization for lighter inference

Real product scraping integration

LLM-generated behavioral explanations

ğŸ† Hackathon Value

This project demonstrates:

Full-stack AI integration

Real ML model training

TorchScript production deployment

Microservice architecture

Zero-budget scalable setup

AMD ROCm compatible training

ğŸ‘¨â€ğŸ’» Author

Siddhant Shitole
AI & Embedded Systems Enthusiast